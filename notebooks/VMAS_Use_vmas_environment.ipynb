{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "VMAS: Use vmas environment.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "0NsC_EwfCF5I"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization"
   ],
   "metadata": {
    "id": "0NsC_EwfCF5I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "! git clone https://github.com/proroklab/VectorizedMultiAgentSimulator.git\n",
    "%cd /content/VectorizedMultiAgentSimulator\n",
    "!pip install -e ."
   ],
   "metadata": {
    "id": "zjnXLxaOMLuv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#@title\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install python3-opengl xvfb\n",
    "!pip install pyvirtualdisplay\n",
    "import pyvirtualdisplay\n",
    "display = pyvirtualdisplay.Display(visible=False, size=(1400, 900))\n",
    "display.start()"
   ],
   "metadata": {
    "id": "1ZpWFjvHOpZJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run\n"
   ],
   "metadata": {
    "id": "jAAA3DXGCLkF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from vmas.simulator.scenario import BaseScenario\n",
    "from typing import Union\n",
    "import time\n",
    "import torch\n",
    "from vmas import make_env\n",
    "\n",
    "def use_vmas_env(\n",
    "    render: bool = False,\n",
    "    save_render: bool = False,\n",
    "    num_envs: int = 32,\n",
    "    n_steps: int = 100,\n",
    "    device: str = \"cpu\",\n",
    "    scenario: Union[str, BaseScenario]= \"waterfall\",\n",
    "    n_agents: int = 4,\n",
    "    continuous_actions: bool = True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Example function to use a vmas environment\n",
    "\n",
    "    Args:\n",
    "        continuous_actions (bool): Whether the agents have continuous or discrete actions\n",
    "        n_agents (int): Number of agents\n",
    "        scenario (str): Name of scenario\n",
    "        device (str): Torch device to use\n",
    "        render (bool): Whether to render the scenario\n",
    "        save_render (bool):  Whether to save render of the scenario\n",
    "        num_envs (int): Number of vectorized environments\n",
    "        n_steps (int): Number of steps before returning done\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    assert not (save_render and not render), \"To save the video you have to render it\"\n",
    "\n",
    "    simple_2d_action = (\n",
    "        [0, -1.0] if continuous_actions else [3]\n",
    "    )  # Simple action for an agent with 2d actions\n",
    "\n",
    "    scenario_name = scenario if isinstance(scenario,str) else scenario.__class__.__name__\n",
    "\n",
    "    env = make_env(\n",
    "        scenario=scenario,\n",
    "        num_envs=num_envs,\n",
    "        device=device,\n",
    "        continuous_actions=continuous_actions,\n",
    "        wrapper=None,\n",
    "        seed=None,\n",
    "        # Environment specific variables\n",
    "        n_agents=n_agents,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    frame_list = []  # For creating a gif\n",
    "    init_time = time.time()\n",
    "    step = 0\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        step += 1\n",
    "        print(f\"Step {step}\")\n",
    "\n",
    "        actions = []\n",
    "        for i, agent in enumerate(env.agents):\n",
    "            action = torch.tensor(\n",
    "                simple_2d_action,\n",
    "                device=device,\n",
    "            ).repeat(num_envs, 1)\n",
    "\n",
    "            actions.append(action)\n",
    "\n",
    "        obs, rews, dones, info = env.step(actions)\n",
    "\n",
    "        if render:\n",
    "            frame = env.render(\n",
    "                mode=\"rgb_array\" if save_render else \"human\",\n",
    "                agent_index_focus=None,  # Can give the camera an agent index to focus on\n",
    "                visualize_when_rgb=True,\n",
    "            )\n",
    "            if save_render:\n",
    "                frame_list.append(frame)\n",
    "\n",
    "    total_time = time.time() - init_time\n",
    "    print(\n",
    "        f\"It took: {total_time}s for {n_steps} steps of {num_envs} parallel environments on device {device} \"\n",
    "        f\"for {scenario_name} scenario.\"\n",
    "    )\n",
    "\n",
    "    if render and save_render:\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        fps=30\n",
    "        clip = ImageSequenceClip(frame_list, fps=fps)\n",
    "        clip.write_gif(f'{scenario_name}.gif', fps=fps)"
   ],
   "metadata": {
    "id": "2Ol4AFeRQ3Ma"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scenario_name=\"waterfall\"\n",
    "use_vmas_env(\n",
    "    scenario=scenario_name,\n",
    "    render=True,\n",
    "    save_render=True,\n",
    "    num_envs=32,\n",
    "    n_steps=150,\n",
    "    device=\"cuda\",\n",
    "    continuous_actions=True,\n",
    "    # Environment specific variables\n",
    "    n_agents=4,\n",
    ")"
   ],
   "metadata": {
    "id": "3cskWki-O8Ul"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image\n",
    "Image(f'{scenario_name}.gif')"
   ],
   "metadata": {
    "id": "UPRa91hMPU1n"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
